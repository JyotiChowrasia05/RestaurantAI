{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFKkfpZ+5ly9JRTs6DaG5u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JyotiChowrasia05/RestaurantAI/blob/main/RestaurantAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "id": "0mzB0n9n27YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "id": "NieIz0hJpCWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install OpenAI"
      ],
      "metadata": {
        "id": "GGlfvtyl3BFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install typing_extensions"
      ],
      "metadata": {
        "id": "eKC84adq3Dfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NbgsvDniiGM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import streamlit as st\n",
        "import langchain\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "w9lVKlyyh1uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.retrievers import AzureCognitiveSearchRetriever\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "import json\n",
        "import os, sys\n",
        "import hashlib\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "USMZm1BbAVZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"a35e69b894d64657ac8fe96a1e98a7d5\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ncus-lfai-nprd-01.openai.azure.com/\"\n",
        "os.environ[\"AZURE_COGNITIVE_SEARCH_SERVICE_NAME\"] = \"lfai-ir-search-service\"\n",
        "os.environ[\"AZURE_COGNITIVE_SEARCH_INDEX_NAME\"] = \"ir-vector-index\"\n",
        "os.environ[\"AZURE_COGNITIVE_SEARCH_API_KEY\"] = \"GFhhonWdwKTTxx1hlEQ98erC4pBqErNcgbOVYcAdNWAzSeCwaydv\"\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\""
      ],
      "metadata": {
        "id": "gmd7zs38zGA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = AzureCognitiveSearchRetriever(content_key=\"chunk\", top_k=2, index_name = \"ir-vector-index\")"
      ],
      "metadata": {
        "id": "pp_0-Sv_1zxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureChatOpenAI(\n",
        "          openai_api_version=\"2023-05-15\",\n",
        "          azure_deployment=\"gpt-35-turbo-16k\",\n",
        "          temperature=0\n",
        "  )"
      ],
      "metadata": {
        "id": "5TCyaqjV_ymo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables=[\"cuisine\"],\n",
        "    template= \"I want to Open a Resaurant for {cuisine} food\"\n",
        ")\n",
        "name_chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
        "\n",
        "#prompt_template_name.format(cuisine=\"Italian\")\n",
        "\n",
        "# prompt_template_items = PromptTemplate(\n",
        "#     input_variables = ['restaurant_name'],\n",
        "#     template = \"Suggest some Menu Item for {restaurant_name}\"\n",
        "# )\n",
        "# items_chain = LLMChain(llm=llm, prompt=prompt_template_items)\n",
        "\n",
        "allchains = SimpleSequentialChain(chains=[name_chain])"
      ],
      "metadata": {
        "id": "MCeV9chdbWgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = allchains.run('Indian')\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Wkpl102QjVfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mychain.run('German')"
      ],
      "metadata": {
        "id": "MFTFzppghI35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [file for file in glob.glob(\"../somefolder/*\")]\n",
        "for file_name in files:\n",
        "    with io.open(file_name, 'rb') as image_file:\n",
        "        content = image_file.read()"
      ],
      "metadata": {
        "id": "LRS9zV5yDjbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "files = os.listdir('./sample_data')\n",
        "\n",
        "# print(len(arr))\n",
        "# for file in files:\n",
        "#   print(file)"
      ],
      "metadata": {
        "id": "GGGA0AnHFWeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_txt = [t for t in os.listdir('./sample_data') if t.endswith(\".txt\")]\n",
        "arr_csv = [c for c in os.listdir('./sample_data') if c.endswith(\".csv\")]\n",
        "arr_pdf = [p for p in os.listdir('./sample_data') if p.endswith(\".pdf\")]\n",
        "\n",
        "print(arr_txt)\n",
        "print(arr_csv)\n",
        "print(arr_pdf)"
      ],
      "metadata": {
        "id": "frdJ4pyWIGn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_files(file):\n",
        "  print(\"Total Text files are:\",file)\n",
        "\n",
        "def get_csv_files(file):\n",
        "  print(\"Total CSV files are:\",file)\n",
        "\n",
        "def get_pdf_files(file):\n",
        "  print(\"Total pdf files are:\",file)\n",
        "\n",
        "for file in os.listdir('./sample_data'):\n",
        "  if file.endswith(\".txt\"):\n",
        "    get_text_files(file)\n",
        "    #print(file)\n",
        "  if file.endswith(\".csv\"):\n",
        "    get_csv_files(file)\n",
        "    #print(file)\n",
        "  if file.endswith(\".pdf\"):\n",
        "    get_pdf_files(file)\n",
        "    #print(file)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y_1_GDAfJGzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Mr. Jyoti like eating Samosa. Mr. Sagar like eating Vada Pav\")\n",
        "print(doc[11])"
      ],
      "metadata": {
        "id": "KXdNAPU8gJyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import textfileext as tf ,pdffileext as pf\n",
        "\n",
        "path = 'C:/Users/jyoti.chowrasia/js/handson_apps/sample_files/'\n",
        "hr_qns=[]\n",
        "\n",
        "def get_text_files(file):\n",
        "    text_arr=[]\n",
        "    text_file_obj = open(file,'r',encoding='cp437')\n",
        "    text_doc = text_file_obj.readline()\n",
        "    text_doc_sentence = sent_tokenize(text_doc)\n",
        "    text_file_obj.close()\n",
        "\n",
        "    for i in range(len(text_doc_sentence)):\n",
        "        #response = \"Q\"+ str(i+1) + \": \" + file_sent[i]\n",
        "        response = \"Q: \"+ text_doc_sentence[i]\n",
        "        text_arr.append(response)\n",
        "    return text_arr\n",
        "\n",
        "def get_pdf_file(file):\n",
        "    pdf_arr=[]\n",
        "    pdf_file_obj = open(file,'rb')\n",
        "    pdf_doc = PyPDF2.PdfReader(pdf_file_obj)\n",
        "    page_len = len(pdf_doc.pages)\n",
        "    pdf_doc_page_obj = pdf_doc.pages[7]\n",
        "    pdf_doc_page_extract = pdf_doc_page_obj.extract_text()\n",
        "    #print(page_extract)\n",
        "    pdf_file_obj.close()\n",
        "    pdf_doc_sentence = sent_tokenize(pdf_doc_page_extract)\n",
        "    #print(pdf_doc_sentence)\n",
        "    for i in range(len(pdf_doc_sentence)):\n",
        "        #response = \"Q\"+ str(i+1) + \": \" + file_sent[i]\n",
        "        response = \"Q: \"+ pdf_doc_sentence[i]\n",
        "        pdf_arr.append(response)\n",
        "        #print(arr)\n",
        "    return pdf_arr\n",
        "\n",
        "for file in os.listdir(path):\n",
        "    if file.endswith('.txt'):\n",
        "       #res = tf.get_text_files(path + file)\n",
        "       res = get_text_files(path + file)\n",
        "       hr_qns.append(res)\n",
        "\n",
        "    if file.endswith('.pdf'):\n",
        "       #res = pf.get_pdf_file(path + file)\n",
        "       res = get_pdf_file(path + file)\n",
        "       hr_qns.append(res)\n",
        "\n",
        "    #if file.endswith('.csv'):\n",
        "    #  get_csv_files(path + file)\n",
        "\n",
        "hr_qns_path = path + \"Hr_QnS.txt\"\n",
        "\n",
        "with open(hr_qns_path, \"w+\",encoding='utf-8') as txt_file:\n",
        "    for line in hr_qns:\n",
        "        txt_file.write(\" \".join(line) + \"\\n\")\n",
        "\n",
        "print(f\"The HR QnS has been written to {hr_qns_path}.\")\n",
        "\n",
        "\n",
        "#print(hr_qns[1])"
      ],
      "metadata": {
        "id": "4-xGBWsoBAKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjzMRcUMxEKL",
        "outputId": "b3a7c660-2c54-4052-ad46-09cf289674e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.0.5.tar.gz (2.4 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "css = \"\"\"\n",
        "  <style>\n",
        "    .chat-message{\n",
        "      padding: 1.5rem; border-radius:0.5rem;margin-bottom: 1rem;display:flex\n",
        "    }\n",
        "    .chat-message.user{\n",
        "      background-color: #475063;\n",
        "    }\n",
        "    .chat-message.avtar{\n",
        "      width:15%\n",
        "    }\n",
        "  </style>\n",
        "\"\"\"\n",
        "bot_template='''\n",
        "  <div class='chat-messaage bot'>\n",
        "    <div class = 'avatar'>\n",
        "      <img src='https://i.ibb.co/qWBwpNb/Photo-logo-5.png' style='max-height:78px;max-width:78px;border-radius:50%'>\n",
        "    </div>\n",
        "  </div>\n",
        "  <!-- <div class='message'>{{msg}}</div>  -->\n",
        "'''\n",
        "user_template='''\n",
        "  <div class='chat-message user'>\n",
        "    <div class='avatar'>\n",
        "      <img src='https://i.ibb.co/rdZC7LZ/Photo-logo-1.png' style='max-height:78px;max-width:78px;border-radius:50%'>\n",
        "    </div>\n",
        "  </div>\n",
        "  <div class='message'>{{msg}}</div>\n",
        "'''"
      ],
      "metadata": {
        "id": "x8kCPU-R3veb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import AzureOpenAIEmbeddings\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from htmltemplate import css,bot_template,user_template\n",
        "\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"a35e69b894d64657ac8fe96a1e98a7d5\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ncus-lfai-nprd-01.openai.azure.com/\"\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
        "model = \"text-embedding-ada-002\"\n",
        "\n",
        "def get_pdf_text(pdf_files):\n",
        "  text = ''\n",
        "  for file in pdf_files:\n",
        "    pdf_reader = PdfReader(file)\n",
        "    for page in pdf_reader.pages:\n",
        "      text += page.extract_text()\n",
        "  return text\n",
        "\n",
        "def get_chunk_text(raw_text):\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "    separator='\\n',\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 20,\n",
        "    length_function = len\n",
        "  )\n",
        "  chunks = text_splitter.split_text(raw_text)\n",
        "  return chunks\n",
        "\n",
        "def get_vectorestore(chunk_text):\n",
        "  embeddings = AzureOpenAIEmbeddings()\n",
        "  vectorstore = FAISS.from_texts(texts=chunk_text, embedding=embeddings)\n",
        "  return vectorstore\n",
        "\n",
        "  #embedding = HuggingFaceInstructEmbeddings(model_name='hkunlp/instructor-xl')\n",
        "\n",
        "\n",
        "def get_conversation_chain(vectorestore_pdf):\n",
        "  llm_pdf = AzureOpenAIEmbeddings(\n",
        "            openai_api_version=\"2023-05-15\",\n",
        "            azure_deployment=\"gpt-35-turbo-16k\",\n",
        "            temperature=0\n",
        "      )\n",
        "  #llm_pdf = ChatOpenAI()\n",
        "  memory_pdf = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "  conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm = llm_pdf,\n",
        "    retriever = vectorestore_pdf.as_retriever(),\n",
        "    memory = memory_pdf\n",
        "  )\n",
        "  return conversation_chain\n",
        "\n",
        "def main():\n",
        "  st.set_page_config(page_title='Chat with Multiple Pdf data',page_icon=':books:')\n",
        "  st.write(css, unsafe_allow_html=True)\n",
        "  if \"conversation\" not in st.session_state:\n",
        "    st.session_state.conversation = []\n",
        "\n",
        "  st.header('Chat with you Data')\n",
        "  st.text_input('Ask your question')\n",
        "\n",
        "  st.write(user_template.replace(\"{{msg}}\",\"Hello Robot\"), unsafe_allow_html=True)\n",
        "  st.write(bot_template.replace(\"{{msg}}\",\"Hello Human\"),unsafe_allow_html=True)\n",
        "\n",
        "  with st.sidebar:\n",
        "    st.subheader('Your document')\n",
        "    pdf_docs = st.file_uploader('Upload your file and click on Process',accept_multiple_files=True)\n",
        "    if st.button('Processs'):\n",
        "      with st.spinner('Processing'):\n",
        "        print('d')\n",
        "        # get the pdf text\n",
        "        raw_text = get_pdf_text(pdf_docs)\n",
        "        #st.write(raw_text)\n",
        "\n",
        "        # get the text chunks\n",
        "        chunk_text = get_chunk_text(raw_text)\n",
        "        st.write(chunk_text)\n",
        "\n",
        "        # create vector store\n",
        "        vectorestore = get_vectorestore(chunk_text)\n",
        "\n",
        "        # create conversation chain\n",
        "        st.session_state.conversation = get_conversation_chain(vectorestore)\n",
        "  st.session_state.conversation\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()\n"
      ],
      "metadata": {
        "id": "9gswtZ-r1QmN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}